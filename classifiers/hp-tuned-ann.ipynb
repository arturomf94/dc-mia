{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "# from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-6, high=1e-1, prior='log-uniform', name='learning_rate')\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "dim_num_dense_nodes = Integer(low=5, high=400, name='num_dense_nodes')\n",
    "dim_activation = Categorical(categories=['relu', 'sigmoid'], name='activation')\n",
    "dim_num_steps = Integer(low = 10, high = 1000, name = 'num_steps')\n",
    "dim_batch_size = Integer(low = 10, high = 500, name = 'batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_dense_layers,\n",
    "              dim_num_dense_nodes,\n",
    "              dim_activation,\n",
    "              dim_num_steps,\n",
    "              dim_batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = [1e-3, 1, 10, 'sigmoid', 100, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir_name(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation, num_steps, batch_size):\n",
    "\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./19_logs/lr_{0:.0e}_layers_{1}_nodes_{2}_{3}/\"\n",
    "\n",
    "    # Insert all the hyper-parameters in the dir-name.\n",
    "    log_dir = s.format(learning_rate,\n",
    "                       num_dense_layers,\n",
    "                       num_dense_nodes,\n",
    "                       activation,\n",
    "                       num_steps,\n",
    "                       batch_size)\n",
    "\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('../data/datosEntrenamiento.csv', header = None)\n",
    "test = pd.read_csv('../data/datosPrueba.csv', header = None)\n",
    "validation = pd.read_csv('../data/datosValidacion.csv', header = None)\n",
    "train=train.rename(columns = {36:'class'})\n",
    "test=test.rename(columns = {36:'class'})\n",
    "train_class_dummies = pd.get_dummies(list(train['class']))\n",
    "train_class_dummies.columns = ['class1','class2','class3','class4','class5','class6']\n",
    "test_class_dummies = pd.get_dummies(list(test['class']))\n",
    "test_class_dummies.columns = ['class1','class2','class3','class4','class5','class6']\n",
    "train = pd.concat([train,train_class_dummies], axis = 1)\n",
    "test = pd.concat([test,test_class_dummies], axis = 1)\n",
    "x_test = test.drop(test.columns[list(range(36,43))], axis = 1).values\n",
    "y_test = test.drop(test.columns[list(range(37))],axis = 1).values\n",
    "x_train = train.drop(train.columns[list(range(36,43))], axis = 1).values\n",
    "y_train = train.drop(test.columns[list(range(37))],axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other parameters\n",
    "num_input = 36\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation, num_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    num_steps:         Epochs\n",
    "    batch_size:        Number of examples per batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer which is similar to a feed_dict in TensorFlow.\n",
    "    model.add(InputLayer(input_shape=(num_input,)))\n",
    "\n",
    "    # The input from MNIST is a flattened array with 784 elements,\n",
    "    # but the convolutional layers expect images with shape (28, 28, 1)\n",
    "    model.add(Reshape((6,6,1)))\n",
    "\n",
    "    # First convolutional layer.\n",
    "    # There are many hyper-parameters in this layer, but we only\n",
    "    # want to optimize the activation-function in this example.\n",
    "    model.add(Conv2D(kernel_size=5, strides=1, filters=16, padding='same',\n",
    "                     activation=activation, name='layer_conv1'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    # Second convolutional layer.\n",
    "    # Again, we only want to optimize the activation-function here.\n",
    "    model.add(Conv2D(kernel_size=5, strides=1, filters=36, padding='same',\n",
    "                     activation=activation, name='layer_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    # Flatten the 4-rank output of the convolutional layers\n",
    "    # to 2-rank that can be input to a fully-connected / dense layer.\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add fully-connected / dense layers.\n",
    "    # The number of layers is a hyper-parameter we want to optimize.\n",
    "    for i in range(num_dense_layers):\n",
    "        # Name of the layer. This is not really necessary\n",
    "        # because Keras should give them unique names.\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "\n",
    "        # Add the dense / fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes and the activation function.\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                        activation=activation,\n",
    "                        name=name))\n",
    "\n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Use the Adam method for training the network.\n",
    "    # We want to find the best learning-rate for the Adam method.\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_best_model = '19_best_model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation, num_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    num_steps:         Epochs\n",
    "    batch_size:        Number of examples per batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print('num_steps:', num_steps)\n",
    "    print('batch_size:', batch_size)\n",
    "    print()\n",
    "    \n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation=activation,\n",
    "                         num_steps = num_steps,\n",
    "                         batch_size = batch_size)\n",
    "\n",
    "    # Dir-name for the TensorBoard log-files.\n",
    "    log_dir = log_dir_name(learning_rate, num_dense_layers,\n",
    "                           num_dense_nodes, activation, num_steps, batch_size)\n",
    "    \n",
    "    # Create a callback-function for Keras which will be\n",
    "    # run after each epoch has ended during training.\n",
    "    # This saves the log-files for TensorBoard.\n",
    "    # Note that there are complications when histogram_freq=1.\n",
    "    # It might give strange errors and it also does not properly\n",
    "    # support Keras data-generators for the validation-set.\n",
    "    callback_log = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        batch_size=batch_size,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False)\n",
    "   \n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=x_train,\n",
    "                        y=y_train,\n",
    "                        epochs=num_steps,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data= (x_test, y_test),\n",
    "                        callbacks=[callback_log],\n",
    "                        verbose = 0)\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_acc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if accuracy > best_accuracy:\n",
    "        # Save the new model to harddisk.\n",
    "        model.save(path_best_model)\n",
    "        \n",
    "        # Update the classification accuracy.\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-03\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 10)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 100)\n",
      "('batch_size:', 50)\n",
      "()\n",
      "()\n",
      "Accuracy: 83.45%\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.8344988297749233"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test run\n",
    "fitness(x=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-03\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 10)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 100)\n",
      "('batch_size:', 50)\n",
      "()\n",
      "()\n",
      "Accuracy: 85.08%\n",
      "()\n",
      "learning rate: 1.5e-06\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 325)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 474)\n",
      "('batch_size:', 485)\n",
      "()\n",
      "()\n",
      "Accuracy: 22.92%\n",
      "()\n",
      "learning rate: 9.2e-02\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 31)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 965)\n",
      "('batch_size:', 166)\n",
      "()\n",
      "()\n",
      "Accuracy: 23.78%\n",
      "()\n",
      "learning rate: 3.0e-03\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 53)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 393)\n",
      "('batch_size:', 47)\n",
      "()\n",
      "()\n",
      "Accuracy: 88.73%\n",
      "()\n",
      "learning rate: 2.8e-06\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 22)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 908)\n",
      "('batch_size:', 193)\n",
      "()\n",
      "()\n",
      "Accuracy: 23.78%\n",
      "()\n",
      "learning rate: 7.6e-04\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 382)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 273)\n",
      "('batch_size:', 92)\n",
      "()\n",
      "()\n",
      "Accuracy: 87.41%\n",
      "()\n",
      "learning rate: 3.0e-05\n",
      "('num_dense_layers:', 4)\n",
      "('num_dense_nodes:', 184)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 193)\n",
      "('batch_size:', 370)\n",
      "()\n",
      "()\n",
      "Accuracy: 84.38%\n",
      "()\n",
      "learning rate: 6.9e-06\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 102)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 46)\n",
      "('batch_size:', 314)\n",
      "()\n",
      "()\n",
      "Accuracy: 22.92%\n",
      "()\n",
      "learning rate: 2.0e-02\n",
      "('num_dense_layers:', 4)\n",
      "('num_dense_nodes:', 376)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 305)\n",
      "('batch_size:', 21)\n",
      "()\n",
      "()\n",
      "Accuracy: 22.92%\n",
      "()\n",
      "learning rate: 9.8e-06\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 76)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 336)\n",
      "('batch_size:', 66)\n",
      "()\n",
      "()\n",
      "Accuracy: 83.45%\n",
      "()\n",
      "learning rate: 4.0e-06\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 36)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 476)\n",
      "('batch_size:', 15)\n",
      "()\n",
      "()\n",
      "Accuracy: 84.30%\n",
      "()\n",
      "learning rate: 3.6e-02\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 103)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 744)\n",
      "('batch_size:', 21)\n",
      "()\n",
      "()\n",
      "Accuracy: 21.76%\n",
      "()\n",
      "learning rate: 6.4e-04\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 5)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 198)\n",
      "('batch_size:', 10)\n",
      "()\n",
      "()\n",
      "Accuracy: 22.92%\n",
      "()\n",
      "learning rate: 8.9e-05\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 185)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 168)\n",
      "('batch_size:', 98)\n",
      "()\n",
      "()\n",
      "Accuracy: 84.30%\n",
      "()\n",
      "learning rate: 5.1e-03\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 156)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 442)\n",
      "('batch_size:', 68)\n",
      "()\n",
      "()\n",
      "Accuracy: 88.42%\n",
      "()\n",
      "learning rate: 1.0e-06\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 166)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 517)\n",
      "('batch_size:', 28)\n",
      "()\n",
      "()\n",
      "Accuracy: 81.43%\n",
      "()\n",
      "learning rate: 1.6e-05\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 185)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 23)\n",
      "('batch_size:', 75)\n",
      "()\n",
      "()\n",
      "Accuracy: 75.99%\n",
      "()\n",
      "learning rate: 4.7e-02\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 294)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 310)\n",
      "('batch_size:', 134)\n",
      "()\n",
      "()\n",
      "Accuracy: 23.78%\n",
      "()\n",
      "learning rate: 7.3e-03\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 245)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 491)\n",
      "('batch_size:', 55)\n",
      "()\n",
      "()\n",
      "Accuracy: 85.24%\n",
      "()\n",
      "learning rate: 1.0e-06\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 374)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 307)\n",
      "('batch_size:', 45)\n",
      "()\n",
      "()\n",
      "Accuracy: 81.04%\n",
      "()\n",
      "learning rate: 2.5e-04\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 5)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 10)\n",
      "('batch_size:', 500)\n",
      "()\n",
      "()\n",
      "Accuracy: 21.76%\n",
      "()\n",
      "learning rate: 5.2e-05\n",
      "('num_dense_layers:', 4)\n",
      "('num_dense_nodes:', 60)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 317)\n",
      "('batch_size:', 209)\n",
      "()\n",
      "()\n",
      "Accuracy: 64.34%\n",
      "()\n",
      "learning rate: 2.9e-04\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 400)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 815)\n",
      "('batch_size:', 10)\n",
      "()\n",
      "()\n",
      "Accuracy: 88.58%\n",
      "()\n",
      "learning rate: 7.5e-06\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 5)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 1000)\n",
      "('batch_size:', 450)\n",
      "()\n",
      "()\n",
      "Accuracy: 40.87%\n",
      "()\n",
      "learning rate: 8.0e-05\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 263)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 88)\n",
      "('batch_size:', 500)\n",
      "()\n",
      "()\n",
      "Accuracy: 79.33%\n",
      "()\n",
      "learning rate: 4.3e-03\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 400)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 73)\n",
      "('batch_size:', 10)\n",
      "()\n",
      "()\n",
      "Accuracy: 80.96%\n",
      "()\n",
      "learning rate: 3.6e-03\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 5)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 1000)\n",
      "('batch_size:', 222)\n",
      "()\n",
      "()\n",
      "Accuracy: 22.92%\n",
      "()\n",
      "learning rate: 2.8e-04\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 200)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 463)\n",
      "('batch_size:', 84)\n",
      "()\n",
      "()\n",
      "Accuracy: 86.87%\n",
      "()\n",
      "learning rate: 9.3e-05\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 321)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 184)\n",
      "('batch_size:', 367)\n",
      "()\n",
      "()\n",
      "Accuracy: 85.63%\n",
      "()\n",
      "learning rate: 7.1e-06\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 71)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 529)\n",
      "('batch_size:', 191)\n",
      "()\n",
      "()\n",
      "Accuracy: 81.97%\n",
      "()\n",
      "learning rate: 3.7e-05\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 386)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 747)\n",
      "('batch_size:', 276)\n",
      "()\n",
      "()\n",
      "Accuracy: 86.64%\n",
      "()\n",
      "learning rate: 5.0e-05\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 98)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 460)\n",
      "('batch_size:', 10)\n",
      "()\n",
      "()\n",
      "Accuracy: 84.85%\n",
      "()\n",
      "learning rate: 1.0e-01\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 349)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 16)\n",
      "('batch_size:', 500)\n",
      "()\n",
      "()\n",
      "Accuracy: 21.76%\n",
      "()\n",
      "learning rate: 1.3e-04\n",
      "('num_dense_layers:', 1)\n",
      "('num_dense_nodes:', 5)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 10)\n",
      "('batch_size:', 10)\n",
      "()\n",
      "()\n",
      "Accuracy: 57.65%\n",
      "()\n",
      "learning rate: 8.8e-05\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 400)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 1000)\n",
      "('batch_size:', 78)\n",
      "()\n",
      "()\n",
      "Accuracy: 80.34%\n",
      "()\n",
      "learning rate: 4.9e-04\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 342)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 869)\n",
      "('batch_size:', 13)\n",
      "()\n",
      "()\n",
      "Accuracy: 89.90%\n",
      "()\n",
      "learning rate: 2.6e-05\n",
      "('num_dense_layers:', 2)\n",
      "('num_dense_nodes:', 277)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 165)\n",
      "('batch_size:', 33)\n",
      "()\n",
      "()\n",
      "Accuracy: 84.07%\n",
      "()\n",
      "learning rate: 3.2e-06\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 39)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 612)\n",
      "('batch_size:', 119)\n",
      "()\n",
      "()\n",
      "Accuracy: 80.65%\n",
      "()\n",
      "learning rate: 4.1e-03\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 254)\n",
      "('activation:', 'relu')\n",
      "('num_steps:', 747)\n",
      "('batch_size:', 10)\n",
      "()\n",
      "()\n",
      "Accuracy: 85.63%\n",
      "()\n",
      "learning rate: 4.8e-04\n",
      "('num_dense_layers:', 5)\n",
      "('num_dense_nodes:', 14)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 683)\n",
      "('batch_size:', 54)\n",
      "()\n",
      "()\n",
      "Accuracy: 88.34%\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# Optimize! \n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=40,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efd90348ed0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEYCAYAAACQgLsAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XuYHGWd9vHvTSaZZBJCTiRGQKIQkYARTRCRAAkExNMinhBRs6ssWdQVl3VfUVxFX1hBZEVfUEF0QUWiIAro4gZiwkFBTZRwSDjISjjFREJCMjkffu8fVZ10Jt0z3T3dXZPq+3NdfU111VPd9xSkf1NPVT+PIgIzM7N62iPrAGZmlj8uLmZmVncuLmZmVncuLmZmVncuLmZmVncuLmZmVncuLmZWEUnjJIWktqyzWN/n4mK5IOn9kuZL6pS0VNJtkqZknatVSTpf0g+zzmHZcXGx3Z6kc4DLgP8AxgAvA74JnJxlrmL+a99ajYuL7dYk7QV8CfhYRNwUEWsjYnNE3BoR/5a2aZd0maTn0sdlktrTbVMlPSPpXyUtT896/iHddoSkv0rqV/R+p0h6IF3eQ9K5kp6QtELSTySNSLcVupA+Iukp4Nfp+g9JWpK2/3dJT0qaXsXrzZD0lKTnJZ1XlKufpM+m+66RtEDSfum2V0m6XdILkh6V9N5ujuc8SV+W9HtJqyXdXMhQou1LJd2Svu6fJf1juv4k4LPAqemZ5MKa/uPabs3FxXZ3RwIDgZ910+Y84A3AYcBrgNcDnyva/hJgL2Af4CPAFZKGR8TvgLXAcUVt3w/8KF3+Z+AdwLHAS4GVwBVd3vtY4GDgTZImkJxRnQ6MLXrPgkpebwpwEHA88HlJB6frzwFOA94CDAU+DKyTNBi4Pc08Gngf8M00SzkfSvcfC2wBvlGm3SzgmTTru4H/kHRcRPyK5CzyxxExJCJe0817WV5FhB9+7LYPkg/qv/bQ5gngLUXP3wQ8mS5PBdYDbUXblwNvSJcvAL6XLu9JUmz2T58vBo4v2m8ssBloA8YBAbyiaPvngeuLnncAm4DpVbzevkXbfw+8L11+FDi5xO9+KnB3l3VXAl8oc6zmARcVPZ+QZuxXlKEN2A/YCuxZ1PbLwDXp8vnAD7P+/8OP7B7uB7bd3QpglKS2iNhSps1LgSVFz5ek67a/Rpd91wFD0uUfAb+VdBbwTuCPEVF4rf2Bn0naVrTvVpLrPgVPd8mx/XlErJO0omh7Ja/31zI59yMpol3tDxwhaVXRujbgByXalsq8BOgPjOrS5qXACxGxpkvbyd28rrUQd4vZ7u5eYCNJd1I5z5F8yBa8LF3Xo4hYRPKh+WZ27hKD5EP4zRExrOgxMCKeLX6JouWlwL6FJ5IGASOrfL1yngYOKLP+zi6vOSQizurmtfYrWn4ZydnT813aPAeMkLRnl7aFrB5uvcW5uNhuLSJeJOluukLSOyR1SOov6c2SvpI2ux74nKS9JY1K21dzm+yPgLOBY4AbitZ/G7hQ0v4A6et3d4fajcDbJb1R0gCSriP14vWKXQ38X0njlZgoaSTwC+CVkj6YHpf+kg4vulZTygckTZDUQXKzxI0RsbW4QUQ8DfwW+LKkgZImklyvKhzXZcA4Sf6MaVH+D2+7vYi4lOSC9ueAv5H8tf5x4OdpkwuA+cADwIPAH9N1lbqe5CL7ryOi+C/4rwO3ALMlrQHuA47oJufDJBftZ5GcxXSSXN/ZWMvrdfGfwE+A2cBq4LvAoLTb6kSSC/nPkXSrXQy0d/NaPwCuSdsOBD5Rpt1pJNdhniO5oeILEXFHuq1QhFdI+mOFv4PliCJ89mqWBUlDgFXA+Ij4S9Z5ILkVmeRC/NVZZ7Hdm89czJpI0tvTrrvBwFdJzqSezDaVWf25uJg118kk3UjPAeNJbiV294HljrvFzMys7nzmYmZmddeyX6IcNWpUjBs3ruS2tWvXMnjw4OYGqpCz1cbZauNstclztgULFjwfEXv32DDrIQKyekyaNCnKmTt3btltWXO22jhbbZytNnnOBsyPCj5j3S1mZmZ15+JiZmZ1l3lxkTQinWvi8fTn8DLtviLpYUmLJX1DktL189I5Ku5PH6Ob+xuYmVlXmRcX4FxgTkSMB+akz3ci6Y3AUcBE4FDgcJLhOApOj4jD0sfyJmQ2M7Nu9IXicjJwbbp8LaVHtw2SMY4GkIyJ1J9kYDwzM+uDMv8SpaRVETEsXRawsvC8S7uvAmeQjCJ7eUScl66fRzJs+Vbgp8AFUeaXknQmcCbAmDFjJs2aNatkps7OToYMGbLL+vsfXcHt9z7Li2s2sdeeAzjhyH047KCRddteiXLZ+gJnq42z1cbZatPbbNOmTVsQET3O29OU77lIuoNkKtmuzit+EhEhaZfCIOlAkqliC3Nh3C7p6Ii4m6RL7Nl0XomfAh8Evl8qR0RcBVwFMHny5Jg6dWrJvPPmzaPrttl3LeLWO+9n48ZkTqkX12zi1jufZsLBB3PiMRN6vb1SpbL1Fc5WG2erjbPVplnZmlJcImJ6uW2SlkkaGxFLJY0lGYK8q1OA+yKiM93nNpK50++OdCKliFgj6Uck86OXLC69ceV192wvDAUbN27hy1f8DzfPfoBFjy9l85atVW+/8rp7qiouZma7g75wzeUWYEa6PAO4uUSbp4BjJbVJ6k9yMX9x+nwUQLr+bcBDjQi5fMXqkus3b9nKwsXP7FI4Kt1e7nXNzHZnfaG4XAScIOlxYHr6HEmTJRXmlLiRZH7wB4GFwMKIuJXk4v7/SHoAuJ9kitXvNCLk6JFDS64fvlcHl3/pVIbv1VHT9nKva2a2O8u8uETEiog4PiLGR8T0iHghXT8/Is5Il7dGxMyIODgiJkTEOen6tRExKSImRsQhEXF2dJmOtV5mnj6F9vadexHb29v457+fymGH7Mc///3UHrf3b9tjl+0zT5/SiLhmZplq2YErq1W4LnLldfewfMVqRo8cyszTp2xfX8n2R55Yxk9+sQCAMaN23m5mlicuLlU48ZgJ3RaDnrZPmXwAP/nFAl57yH78vy+d2oiIZmZ9QubdYq2kY9AAANau35RxEjOzxnJxaaJCcVnn4mJmOefi0kQdHUlxWe/iYmY55+LSRB0DC91iGzNOYmbWWC4uTTRoYH8k2LBxC1u3bss6jplZw7i4NJGk7ddd1m/YnHEaM7PGcXFpMneNmVkrcHFpMt8xZmatwMWlyQp3jK1b724xM8svF5cmK3SLrXO3mJnlmItLk7lbzMxagYtLkw3ucHExs/xzcWmyHXeLubiYWX65uDSZu8XMrBW4uDTZ4I52wMXFzPLNxaXJOgb2B9wtZmb55uLSZO4WM7NW4OLSZB3uFjOzFuDi0mQ7vkTp4mJm+eXi0mTuFjOzVuDi0mT+EqWZtQIXlyYrnLn4bjEzyzMXlybzNRczawUuLk02KP2ey/oNm9i2LTJOY2bWGC4uTdav3x4MGtifCNiw0XO6mFk+ubhkwF1jZpZ3Li4Z6PAdY2aWcy4uGdhxx5hnozSzfHJxycCObjFfczGzfHJxyYC/SGlmeZd5cZE0QtLtkh5Pfw4v0+4rkh6WtFjSNyQpXT9A0lWSHpP0iKR3Nfc3qN72brF17hYzs3zKvLgA5wJzImI8MCd9vhNJbwSOAiYChwKHA8emm88DlkfEK4EJwJ3NCN0b27vFNvjMxczyqS3rAMDJwNR0+VpgHvDpLm0CGAgMAAT0B5al2z4MvAogIrYBzzc0bR34bjEzyztFZPstcUmrImJYuixgZeF5l3ZfBc4gKS6XR8R5koYBDwI3kBSoJ4CPR8Syrvunr3EmcCbAmDFjJs2aNatkps7OToYMGdLbX62suX94jjn3Pcexk1/CCUfuW9W+jc7WG85WG2erjbPVprfZpk2btiAiJvfYMCIa/gDuAB4q8TgZWNWl7coS+x8I/BIYkj7uBY4GRpGc1bw7bXcO8INKMk2aNCnKmTt3btlt9fDjW+fHUe+8JL529R1V79vobL3hbLVxtto4W216mw2YHxV8xjalWywippfbJmmZpLERsVTSWGB5iWanAPdFRGe6z23AkcA9wDrgprTdDcBH6hq+AXy3mJnlXV+4oH8LMCNdngHcXKLNU8Cxktok9Se5mL84raK3suOazfHAosbG7b0dd4u5uJhZPvWF4nIRcIKkx4Hp6XMkTZZ0ddrmRpLrKQ8CC4GFEXFruu3TwPmSHgA+CPxrM8PXwneLmVneZX63WESsIDnj6Lp+PskFfCJiKzCzzP5LgGMambHePNWxmeVdXzhzaTmFay7uFjOzvHJxyYC7xcws71xcMuBuMTPLOxeXDBQXl8j4S6xmZo3g4pKBtrZ+DBjQxrZtwcZNW7KOY2ZWdy4uGekY2B9w15iZ5ZOLS0YGd7QDvmPMzPLJxSUj26+7+I4xM8shF5eMFG5H9oRhZpZHFRcXSe+RtGe6/DlJN0l6XeOi5duOwSs3Z5zEzKz+qjlz+feIWCNpCskYYN8FvtWYWPk3yF+kNLMcq6a4bE1/vhW4KiJ+STIzpNVg+zUXd4uZWQ5VU1yelXQV8D7gvyW1V7m/FfGcLmaWZ9UUh/cAtwEnRMQqYDjwqYakagEeAsbM8qzHIfclrSGZShiS+esjmeo+WQaGNixdjm2/W8zFxcxyqMfiEhF7NiNIq3G3mJnlma+ZZMTdYmaWZ9V0i6nE5ogId4vVwN1iZpZn7hbLSEfaLbbexcXMcqjH4lJM0nBgPDCwsC4i7qp3qFbgbjEzy7OKi4ukM4CzgX2B+4E3APcCxzUmWr65W8zM8qyaC/pnA4cDSyJiGvBaYFVDUrUA3y1mZnlWTXHZEBEbACS1R8QjwEGNiZV/xUPue6pjM8ubaq65PCNpGPBz4HZJK4EljYmVfwP6t9HWtgdbtmxj0+attA+o6vKXmVmfVvEnWkScki6eL2kusBfwq4akahGDB7Xz4pr1rFu/ycXFzHKlpk+0iLiz3kFaUceg/tuLy/C9OrKOY2ZWN9VMFnZt2i1WeD5c0vcaE6s1FO4Y80V9M8ubai7oT0xHQwYgIlaS3DFmNeroaAdcXMwsf6opLnukX6IEQNIIauxWs0THoP6Ai4uZ5U81xeFS4F5JN6TP3wNcWP9IrcNfpDSzvKrmbrHvS5rPjm/kvzMiFjUmVmsY7G4xM8upqrq10mLiglInHl/MzPIq8/lcJI2QdLukx9Ofw8u0+4qkhyUtlvQNJfaUdH/R43lJlzX7d6hVx8Dkmsva9RszTmJmVl+ZFxfgXGBORIwH5qTPdyLpjcBRwETgUJIxzo6NiDURcVjhQTJiwE3Ni947vlvMzPKqmlGRjwNOJxms8iHgAeChiOjtn90nA1PT5WuBecCnu7QJkmH+B5BMWtYfWNYl3yuB0cDdvczTNDu6xTZnnMTMrL5U6aCJkp4EPknywT4xfRwSEQf2KoC0KiKGpcsCVhaed2n3VeAMkuJyeUSc12X754GhEfGpbt7rTOBMgDFjxkyaNWtWyXadnZ0MGTKkxt+ocgsfXcENs//Cq8cP59STDqhon2Zlq4Wz1cbZauNstelttmnTpi2IiMk9NoyIih7AnZW2LbHvHSRnO10fJwOrurRdWWL/A4FfAkPSx73A0V3aLAImVZpp0qRJUc7cuXPLbqune/7w5zjqnZfEpy64seJ9mpWtFs5WG2erjbPVprfZgPlRwWdsNXeL3SXpX4DL0jeoWERML7dN0jJJYyNiqaSxwPISzU4B7ouIznSf24AjSbvAJL0GaIuIBdXkypq7xcwsr6q5oD8BOAtYKumXki6U9J46ZLgFmJEuzwBuLtHmKeBYSW2S+gPHAouLtp8GXF+HLE1VKC6+W8zM8qbi4hIR74qIVwIvBz4PPA4cUYcMFwEnSHocmJ4+R9JkSVenbW4EngAeBBYCCyPi1qLXeC+7YXEZ7O+5mFlOVT02WESsBxakj16LiBXA8SXWzye5gE9EbAVmdvMar6hHlmbzlyjNLK/6wvdcWpaLi5nllYtLhtoHtNFvD7Fp81a2bNmadRwzs7qpqLikQ63s1+gwrUYSg3z2YmY5VFFxSW89/u8GZ2lJO+4Yc3Exs/yoplvsj5IOb1iSFuU7xswsj6q5W+wI4APpMDBrSYZhiYiY2IhgrcIX9c0sj6opLm9qWIoW5m4xM8ujarrFngKOBmZExBKSkYrHNCRVC3G3mJnlUTXF5Zsk43mdlj5fA1xR90Qtxt1iZpZHVV1ziYjXSfoTQESslDSgQblahouLmeVRNWcumyX1I+kOQ9LewLaGpGohHYM8G6WZ5U81xeUbwM+A0ZIuBO4BvtyQVC2kY1B/wMXFzPKl4m6xiLhO0gKSQSYFvCMiFvewm/XAd4uZWR5VXFwkXRwRnwYeKbHOajTY3WJmlkPVdIudUGLdm+sVpFX5gr6Z5VGPZy6SzgI+CrxC0gNFm/YEftOoYK3Cs1GaWR5V0i32FuBtwKPA24vWr4mIFxqSqoXs+BLl5oyTmJnVTyXF5QBgM0lxWU1yMR8ASSNcYHrH3WJmlkeVFJdvA3OAl5NMbayibQHsllMM9xU7iou7xcwsP3q8oB8R34iIg4H/iohXRMTLix4uLL3kMxczy6NqvudylqThwHhgYNH6uxoRrFUMGtgfCTZs3MLWrdvo188zT5vZ7q+a77mcAZwN7AvcD7wBuBc4rjHRWoMkBg0cwLr1m1i3YRN7Dh7Y805mZn1cNX8mnw0cDiyJiGnAa4FVDUnVYjzsvpnlTTXFZUNEbACQ1B4RjwAHNSZWa/F1FzPLm2qG3H9G0jDg58DtklYCSxoTq7V4fDEzy5tqLuifki6eL2kusBfwq4akajGF4rLexcXMcqKaM5ftIuLOegdpZe4WM7O88X2vfcD2brF1Li5mlg8uLn3A9rvFNri4mFk+VF1cJA1Opzu2OnG3mJnlTY/FRdIekt4v6ZeSlpNMFrZU0iJJl0g6sPEx883dYmaWN5WcucwlGRn5M8BLImK/iBgNTAHuAy6W9IEGZsw9d4uZWd5UcrfY9IjYZbKRdKj9nwI/ldS/1gCSRgA/BsYBTwLvjYiVJdp9BXgrSUG8HTg7IkLSacBnSUZofg74QEQ8X2ueLLhbzMzyppJRkTcDSPq6JHXXpkbnAnMiYjzJ0P7ndm0g6Y3AUcBE4FCSYWiOldQGfB2YFhETgQeAj/ciSya2Fxd3i5lZTlRzQX8NcIukwQCS3iSpHtMcnwxcmy5fC7yjRJsgGYl5ANAO9AeWkcwtI2BwWviGkpy97FY6BrUD7hYzs/xQRFTeWHo/8C/AJqATuCAi7u5VAGlVRAxLlwWsLDzv0u6rwBkkxeTyiDgvXf9u4HvAWuBxkrOYrWXe60zgTIAxY8ZMmjVrVslMnZ2dDBkypDe/VlWe/msnV97wCPuM7uCsUyd027bZ2arhbLVxtto4W216m23atGkLImJyjw0joqIHcDzJxf15JFMeH1TFvncAD5V4nAys6tJ2ZYn9DwR+CQxJH/cCR5OcwcwhueFAwOXA5yrJNGnSpChn7ty5Zbc1wv8+9bc46p2XxGkf/26PbZudrRrOVhtnq42z1aa32YD5UcFnbDXDv5wH/HtE3CPp1cCPJZ0TEb+uoIBNL7dN0jJJYyNiqaSxwPISzU4B7ouIznSf24AjgQ3p6z+Rrv8JJa7Z9HWDO9wtZmb5UvE1l4g4LiLuSZcfBN4MXFCHDLcAM9LlGcDNJdo8RXoBP70z7VhgMfAsMEHS3mm7E9L1u5WOgb5bzMzypZIvUZa7Q2wpSVdZ2TYVugg4QdLjwPT0OZImS7o6bXMj8ATwILAQWBgRt0bEc8AXgbskPQAcBvxHL7JkYtDA5E7udes3sW1b5dfAzMz6qkq6xeZK+ilwc0Q8VVgpaQBwpKQZJNdirqklQESsIC1SXdbPJ7mATyQX6GeW2f/bwLdree++ol+/PRg0sD/rN2xmw8bN229NNjPbXVVSXE4CPgxcL+nlJFMbDwT6AbOByyLiT42L2Bo6Bg5g/YbNrFu/ycXFzHZ7lRSXiyPibEnXAJuBUcD6iFjV0GQtZtCgAbBqLWvXbWTUiL55C6OZWaUquaB/TPrz7ojYHBFLXVjqb3CHxxczs/yopLjMkXQv8BJJH5Y0SVJ7o4O1mh13jPVmJB0zs76hx26xiPiUpANILtq/HPg74BBJm4CHIuLUBmdsCTuG3d+YcRIzs96r6EuUEfGEpOkR8VhhnaQhJINIWh1s7xbzd13MLAeq+Yb+knRssXFd9ruvrolaVKFbbK2Li5nlQDXF5WbgRWAB4L6bOvOcLmaWJ9UUl30j4qSGJWlxHe4WM7McqWY+l9+mA1ZaA3h8MTPLk2rOXKYAfy/pLyTdYgIikhkgrZfcLWZmeVJNcXlzw1KY7xYzs1ypuLhExJJGBml1vlvMzPKkkiH370l/rpG0Ov1ZeKxufMTW4G4xM8uTSr6hPyX9uWfj47Qud4uZWZ5U3C0maTLwWbp8idIX9OvDd4uZWZ5Uc0H/OuDfSGaD3NaYOK3L3WJmlifVFJe/RcQtDUvS4rYXlw2biAh6N3O0mVm2qikuX0jntJ9D0fAvEXFT3VO1oLa2fgwY0MamTVvYsHEzgwZ6Nkoz231VU1z+AXgV0J8d3WIBuLjUScfA/mzatIV1611czGz3Vk1xOTwiDmpYEmNwRzurVq9n3fpNjBw+OOs4ZmY1q6a4/FbShIhY1LA0LWz2XYtY9rfka0Mf+/dZfHzGsZx4zISdtl953T0se341Y65/jJmnTym5ffmK1YweObSu2yvd19mczdm6z9ZKFBGVNZQWAwcAuRhbbPLkyTF//vyS2+bNm8fUqVOblmX2XYu4+Nuz2bhxy/Z17e1tfPqfTuTEYyZkuh1wNmdztjpk6yt6+/kmaUFETO6xXRXFZf9S63fXYWH6UnF518yrWPb8roMd7CExbK9BrHpxPdtK/HdqxnYgs/d2NmfLQ7Yxo4by0yvP3GV9VppVXDy2WB+wfEXpUXS2RfDCqnVl92vG9izf29mcLQ/Zyv37zrtq5nOxBhk9cmjJ9XuPGMLNV5/F3iOGZLY9y/d2NmfLQ7Zy/77zzsWlD5h5+hTa23c+iWxvb+OsDx7DyOGDOeuDx2S2Pcv3djZny0O2madPoRX1O//887POkImrrrrq/DPPLN0P+uSTTzJu3LimZTlg/70Zu/dQHnliGevWb2TMqKGc/eFp2y8CFm9fu6777T3tX+12Z3M2Z6su24OPPsf6DZvp128PPvPRN/Wpi/nQ+8+3L37xi0vPP//8q3psGBEt+Zg0aVKUM3fu3LLbsuZstXG22jhb9dat3xhHvfOSOPa9l8bmLVuzjrOL3h43YH5U8BnrbjEzszoaNHAAw/YcwJYt23jur6uyjpMZFxczszobPWIgAH95ZkXGSbLj4mJmVmd7jxgEwJNPu7hkRtIISbdLejz9ObxMu69IeljSYknfUDomvaRTJT2Qbru4uenNzHY1ulBcfOaSqXOBORExnmQ4/3O7NpD0RuAoYCJwKHA4cKykkcAlwPERcQjwEknHNy25mVkJhW6xJS4umToZuDZdvhZ4R4k2AQwEBgDtJMP+LwNeATweEX9L290BvKuhac3MerD38KS4PPnsC2zd2poT91Y8tljDAkirImJYuixgZeF5l3ZfBc4gGTDz8og4L+1CexCYAjwD/BgYEBFvL/NeZwJnAowZM2bSrFmzSmbq7OxkyJDS37bNmrPVxtlq42y16ezs5IqfPMGatZs550OvZsRe7VlH2q63x23atGn1HVusNyTdAbykxKbzip9EREjapdpJOhA4GNg3XXW7pKMj4m5JZ5EUlW3Ab0lGbi4pIq4CroJk4Mpyg7c1e+DKajhbbZytNs5Wm3nz5nHQAS9l/gNLGLPPgRw1uezHUtM167g1pVssIqZHxKElHjcDyySNBUh/Li/xEqcA90VEZ0R0ArcBR6avfWtEHBERRwKPAo8143cyM+vOuH1HAq17Ub8vXHO5BZiRLs8Abi7R5imSC/htkvoDxwKLASSNTn8OBz4KXN3wxGZmPRi3X1JcWvWifl8oLhcBJ0h6HJiePkfSZEmFQnEj8ATJ9ZWFwMKIuDXd9nVJi4DfABdFhM9czCxz4/YZAbTuFymbcs2lOxGxAtjl9uGImE9yAZ+I2ArMLLP/aQ0NaGZWg8KZy5NPryAiSL+a1zL6wpmLmVnuDBvawbChg1i/YTPLV6zJOk7TubiYmTXIjusuL2ScpPlcXMzMGmTcPq17x5iLi5lZgxTOXP7SggNYuriYmTVIK3/XxcXFzKxBtt8x9kxyx1grcXExM2uQkcMGM2RwO2s6N7DyxXVZx2kqFxczswaRtKNrrMWuu7i4mJk1UKG4tNo39V1czMwaqFUv6ru4mJk1UKsOYOniYmbWQIUBLH3mYmZmdTN61FAGDezPC6vW8eKa9VnHaRoXFzOzBtpjD7F/C569uLiYmTVY8fD7rcLFxcyswQp3jC15tnVGR3ZxMTNrsFb8IqWLi5lZg7Xid11cXMzMGmzs6L0Y0L8fy1esYe26jVnHaQoXFzOzBuvXbw9elt4x1irXXVxczMyaYP99Wuu6i4uLmVkTvHy/1rru4uJiZtYErXZR38XFzKwJxvnMxczM6m3flwyjX789WLr8RTZs3Jx1nIZzcTEza4K2tn7sN3YYEfBUC9wx5uJiZtYkrXTdxcXFzKxJtk953AK3I7dlHcDMrFWs7twAwA9u+h2z71rMzNOncOIxE7Zvn33XIq687h6Wr1jN6JFDq9pe6b7Lnl/NmOsf22V7vbm4mJk1wey7FvGLOQ9uf77s+dVc/K3ZrF23ialHvpJ59z7G5dfOY+OmLVVvB6rf99uzARpWYFxczMya4Mrr7mHT5q07rdu4aQuXfucOLv3OHSX3qXR7Tftu3MKV193TsOLiay5mZk2wfMXqstuGDR3U7b49ba913+4y9VbmxUXSCEm3S3o8/Tm8TLuLJT2UPk4tWv9ySb+T9GdJP5Y0oHnpzcwqM3rk0JLrx4wayi/+62OMGVX79lr3LZepHjIvLsC5wJyIGA/MSZ/vRNJbgdcBhwFHAJ/1ejtoAAAJHElEQVSSVDgqFwNfi4gDgZXAR5qS2sysCjNPn0J7+85XItrb25h5+pReb+/tazdCX7jmcjIwNV2+FpgHfLpLmwnAXRGxBdgi6QHgJEk3AMcB7y/a/3zgW42NbGZWncK1jXJ3dPV2e6X7Lnt+NWNG7bpvvSkiGvbiFQWQVkXEsHRZwMrC86I2JwJfAE4AOoDfA1eQFJP70rMWJO0H3BYRh5Z5rzOBMwHGjBkzadasWSUzdXZ2MmTIkDr8dvXnbLVxtto4W23ynG3atGkLImJyjw0jouEP4A7goRKPk4FVXdquLPMa5wH3A7cD1wGfBEYBfy5qsx/wUCWZJk2aFOXMnTu37LasOVttnK02zlabPGcD5kcFn7FN6RaLiOnltklaJmlsRCyVNBZYXuY1LgQuTPf5EfAYsAIYJqktki6zfYFn6/4LmJlZVfrCBf1bgBnp8gzg5q4NJPWTNDJdnghMBGanVXQu8O7u9jczs+bqC8XlIuAESY8D09PnSJos6eq0TX/gbkmLgKuAD6RnKpBc/D9H0p+BkcB3m5rezMx2kfndYhGxAji+xPr5wBnp8gaSO8ZK7f+/wOsbmdHMzKqT+d1iWZH0N2BJmc2jgOebGKcazlYbZ6uNs9Umz9n2j4i9e2rUssWlO5LmRyW32mXA2WrjbLVxtto4W9+45mJmZjnj4mJmZnXn4lLaVVkH6Iaz1cbZauNstWn5bL7mYmZmdeczFzMzqzsXFzMzqzsXly4knSTp0XTysV3mlsmSpCclPSjpfknzM87yPUnLJT1UtK6iid8yyna+pGfTY3e/pLdklG0/SXMlLZL0sKSz0/WZH7tusmV+7CQNlPR7SQvTbF9M12c+WWA32a6R9Jei43ZYs7OlOfpJ+pOkX6TPm3LMXFyKSOpHMpT/m0lGBDhNUuMmPKjNtIg4rA/cQ38NcFKXdT1O/NYk17BrNkgmlTssffx3kzMVbAH+NSImAG8APpb+P9YXjl25bJD9sdsIHBcRryGZNPAkSW+gb0wWWC4bwL8VHbf7M8gGcDawuOh5U46Zi8vOXk8yhP//RsQmYBbJtADWRUTcBbzQZfXJJHPskP58R1NDpcpk6xMiYmlE/DFdXkPyj34f+sCx6yZb5tLR3jvTp/3TR5BMFnhjuj6r41YuW+Yk7Qu8Fbg6fS6adMxcXHa2D/B00fNn6CP/uFIBzJa0IJ34rK8ZExFL0+W/AmOyDFPCxyU9kHabZdJlV0zSOOC1wO/oY8euSzboA8cu7d65n2RajtuBJ0jmgyoMYpvZv9eu2SKicNwuTI/b1yS1ZxDtMuD/ANvS5yNp0jFzcdm9TImI15F0231M0jFZByonnQ6hT/z1lvoWcABJt8VS4NIsw0gaAvwU+GRErC7elvWxK5GtTxy7iNgaEYeRzNv0euBVWeQopWs2SYcCnyHJeDgwgl2nb28oSW8DlkfEgma+b4GLy86eJZnNsqBPTT4WEc+mP5cDP6PvjQa9LJ3wje4mfstCRCxLPwC2Ad8hw2MnqT/Jh/d1EXFTurpPHLtS2frSsUvzrCKZx+lI0skC002Z/3stynZS2s0YEbER+C+af9yOAv5O0pMkXfzHAV+nScfMxWVnfwDGp3dTDADeRzKZWeYkDZa0Z2EZOJFkqui+pMeJ37JS+OBOnUJGxy7t8/4usDgi/rNoU+bHrly2vnDsJO0taVi6PAg4geSaUOaTBZbJ9kjRHwsiua7R1OMWEZ+JiH0jYhzJZ9mvI+J0mnXMKpkLuZUewFtIplB+Ajgv6zxFuV4BLEwfD2edDbiepItkM0m/7UdI+nPnAI8DdwAj+lC2HwAPAg+QfJCPzSjbFJIurweA+9PHW/rCsesmW+bHjmT22T+lGR4CPp+ufwXwe+DPwA1Aex/K9uv0uD0E/BAYksX/c2mWqcAvmnnMPPyLmZnVnbvFzMys7lxczMys7lxczMys7lxczMys7lxczMys7lxczMys7lxczMys7lxcrCVICkmXFj3/lKTz6/C644rnjWkkSZ+QtFjSdb18nc5Sy2b15OJirWIj8E5Jo7IOUkyJSv8dfhQ4IZIhPMz6NBcXaxVbgKuAfyle2fXMo3BGk65/JJ1N8DFJ10maLuk3SmaLLB6EsC3dvljSjZI60tf6QDpD4f2Srkwnoyu856OSvk8yNMh+XTKdI+mh9PHJdN23SYbtuE3STr9Duv1D6dDuCyX9IF3383R6hod7mqIhHbvul+n+D0k6tUSbmyRdIOkuSU9Jmt7da1prc3GxVnIFcLqkvSpsfyDJ8PKvSh/vJxl/61PAZ4vaHQR8MyIOBlYDH5V0MHAqcFQkQ7FvBYrPOMan+xwSEUsKKyVNAv4BOIJkNsh/lPTaiPgn4DmSmUi/VhxS0iHA59gxG+LZ6aYPR8QkYDLwCUkju/ldTwKei4jXRMShwK9KtHk1yVwgx6Tv4TMoK8vFxVpGJHOTfB/4RIW7/CUiHoxkqPmHSaYhDpLBCMcVtXs6In6TLv+QpAAdD0wC/pBOInU8yZlHwZKIuK/Ee04BfhYRayOZ3fAm4Ogech4H3BARz6e/Z2EWzk9IWgjcR3J2NL6b13gQOEHSxZKOjogXizemZ2N7AYXC1h9Y1UMua2FtPTcxy5XLgD+SzK8BSXdZ8R9ZA4uWNxYtbyt6vo2d/+10Hf01AAHXRsRnyuRYW0XmqkmaCkwHjoyIdZLmsfPvtpOIeEzS60hGQb5A0pyI+FJRkwnAgojYmj6fSN+b8sH6EJ+5WEtJ/6r/Cckw/ADLgNGSRqbT0L6thpd9maQj0+X3A/eQDJ//bkmjASSNkLR/Ba91N/AOSR3pvD2npOu682vgPYVuL0kjSM4yVqaF5VUkXWxlSXopsC4ifghcAryuS5NXkwzBXzCRZIh5s5J85mKt6FLg4wARsVnSl0jmt3gWeKSG13uUZNrp7wGLgG+lH+qfA2and4NtBj4GLOnmdYiIP0q6Js0DcHVE/KmHfR6WdCFwp6StJHOLzAT+SdLiNF+pLrhirwYukbQtzXpWie2/K3p+KD5zsW54PhczM6s7d4uZmVndubiYmVndubiYmVndubiYmVndubiYmVndubiYmVndubiYmVnd/X/9fxqJbaKk5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0004909617858915018, 3, 342, 'sigmoid', 869, 13]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = search_result.space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8989899050105702"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.8989899050105702, [0.0004909617858915018, 3, 342, 'sigmoid', 869, 13]),\n",
       " (-0.8873349003024869, [0.0029624764954723814, 3, 53, 'relu', 393, 47]),\n",
       " (-0.885780879621276, [0.0002880377959911072, 5, 400, 'sigmoid', 815, 10]),\n",
       " (-0.8842268808923587, [0.005079923195031496, 3, 156, 'relu', 442, 68]),\n",
       " (-0.8834498849782076, [0.00048276935454609433, 5, 14, 'sigmoid', 683, 54]),\n",
       " (-0.8741258813043667, [0.0007587758099812466, 2, 382, 'sigmoid', 273, 92]),\n",
       " (-0.8686868737349699, [0.0002801818975887996, 1, 200, 'sigmoid', 463, 84]),\n",
       " (-0.8663558650127936, [3.732339814844498e-05, 2, 386, 'relu', 747, 276]),\n",
       " (-0.8562548602840747, [9.285620188816448e-05, 2, 321, 'relu', 184, 367]),\n",
       " (-0.8562548516235707, [0.004053286309525292, 3, 254, 'relu', 747, 10]),\n",
       " (-0.852369856630635, [0.007309461605441057, 5, 245, 'relu', 491, 55]),\n",
       " (-0.8508158492875266, [0.001, 1, 10, 'sigmoid', 100, 50]),\n",
       " (-0.8484848445482558, [5.049843275659828e-05, 5, 98, 'sigmoid', 460, 10]),\n",
       " (-0.8438228513718392, [2.9502954098419526e-05, 4, 184, 'relu', 193, 370]),\n",
       " (-0.8430458521231626, [3.994656338163535e-06, 2, 36, 'relu', 476, 15]),\n",
       " (-0.8430458491591399, [8.863857845404172e-05, 2, 185, 'sigmoid', 168, 98]),\n",
       " (-0.8407148504868532, [2.5894976162848836e-05, 2, 277, 'sigmoid', 165, 33]),\n",
       " (-0.8344988364439744, [9.766764817607654e-06, 3, 76, 'relu', 336, 66]),\n",
       " (-0.8197358197821326, [7.1451502896100155e-06, 2, 71, 'relu', 529, 191]),\n",
       " (-0.8142968111012273, [1e-06, 3, 166, 'relu', 517, 28]),\n",
       " (-0.8104118212953314, [1e-06, 3, 374, 'relu', 307, 45]),\n",
       " (-0.8096348066939433, [0.004267052504516121, 5, 400, 'relu', 73, 10]),\n",
       " (-0.8065268168545733, [3.1917118199671707e-06, 3, 39, 'relu', 612, 119]),\n",
       " (-0.803418800686345, [8.833367987485881e-05, 5, 400, 'sigmoid', 1000, 78]),\n",
       " (-0.7933177759967854, [8.020841708751822e-05, 1, 263, 'relu', 88, 500]),\n",
       " (-0.7599067637970397, [1.646405885560152e-05, 1, 185, 'relu', 23, 75]),\n",
       " (-0.6433566533602201, [5.245398833841211e-05, 4, 60, 'sigmoid', 317, 209]),\n",
       " (-0.576534579267035, [0.00012559650078181422, 1, 5, 'sigmoid', 10, 10]),\n",
       " (-0.4087024118516829, [7.528690742575396e-06, 5, 5, 'relu', 1000, 450]),\n",
       " (-0.23776223949896982, [0.046502846837188826, 2, 294, 'sigmoid', 310, 134]),\n",
       " (-0.23776223831220292, [2.7836125715639146e-06, 5, 22, 'sigmoid', 908, 193]),\n",
       " (-0.23776223607181854, [0.0921135182640834, 1, 31, 'sigmoid', 965, 166]),\n",
       " (-0.229215235620876, [0.019830371607497142, 4, 376, 'sigmoid', 305, 21]),\n",
       " (-0.2292152336192923, [0.003638628722707952, 5, 5, 'relu', 1000, 222]),\n",
       " (-0.22921523217925197, [6.915125464291622e-06, 3, 102, 'sigmoid', 46, 314]),\n",
       " (-0.22921523180874911, [0.0006409867246696217, 3, 5, 'relu', 198, 10]),\n",
       " (-0.22921522177622683, [1.5272695961493874e-06, 2, 325, 'sigmoid', 474, 485]),\n",
       " (-0.2175602219859898, [0.03608047269292175, 3, 103, 'relu', 744, 21]),\n",
       " (-0.21756021992217317, [0.0002451828961403742, 1, 5, 'sigmoid', 10, 500]),\n",
       " (-0.21756021992217317, [0.1, 1, 349, 'sigmoid', 16, 500])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(search_result.func_vals, search_result.x_iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New function to save model in proper filepath\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness2(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation, num_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    num_steps:         Epochs\n",
    "    batch_size:        Number of examples per batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print('num_steps:', num_steps)\n",
    "    print('batch_size:', batch_size)\n",
    "    print()\n",
    "    \n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation=activation,\n",
    "                         num_steps = num_steps,\n",
    "                         batch_size = batch_size)\n",
    "\n",
    "    # Dir-name for the TensorBoard log-files.\n",
    "    log_dir = log_dir_name(learning_rate, num_dense_layers,\n",
    "                           num_dense_nodes, activation, num_steps, batch_size)\n",
    "    \n",
    "    # Create a callback-function for Keras which will be\n",
    "    # run after each epoch has ended during training.\n",
    "    # This saves the log-files for TensorBoard.\n",
    "    # Note that there are complications when histogram_freq=1.\n",
    "    # It might give strange errors and it also does not properly\n",
    "    # support Keras data-generators for the validation-set.\n",
    "    callback_log = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        batch_size=batch_size,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False)\n",
    "   \n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=x_train,\n",
    "                        y=y_train,\n",
    "                        epochs=num_steps,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data= (x_test, y_test),\n",
    "                        callbacks=[callback_log],\n",
    "                        verbose = 0)\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_acc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    # Save the new model to harddisk.\n",
    "    model.save('final.h5')\n",
    "        \n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 4.9e-04\n",
      "('num_dense_layers:', 3)\n",
      "('num_dense_nodes:', 342)\n",
      "('activation:', 'sigmoid')\n",
      "('num_steps:', 869)\n",
      "('batch_size:', 13)\n",
      "()\n",
      "()\n",
      "Accuracy: 89.67%\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.8966589028185065"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness2(search_result.x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc-mia",
   "language": "python",
   "name": "dc-mia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
